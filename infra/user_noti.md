# ğŸ“‚ ëª©ë¡

- [Minio êµ¬ì¶•í•˜ê¸°](./minio.md)
- [ClickHouse êµ¬ì¶•í•˜ê¸°](./clickhouse.md)
- [Redis êµ¬ì¶•í•˜ê¸°](./reids.md)
- [ì‚¬ìš©ì ì•Œë¦¼ ë° ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬](./user_noti.md)

# ì‚¬ìš©ì ì•Œë¦¼ ë° ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬

ì»¤ë®¤ë‹ˆí‹°ë¥¼ ê°œë°œí•˜ë©´ì„œ ëŒ“ê¸€, ì¢‹ì•„ìš”, íŒ”ë¡œì›Œ ê¸€ ì‘ì„± ë“±ì˜ ê¸°ëŠ¥ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ì´ ê°€ê²Œ í•˜ëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•¨ì„ ëŠê¼ˆìŠµë‹ˆë‹¤.  
ë‹¤í–‰íˆë„ ê¸°ì¡´ì— ì‚¬ìš©ì ë°©ë¬¸ í†µê³„ì— Kafkaë¥¼ ìš´ìš©í•˜ê³  ìˆì–´ì„œ, Redisì™€ WebSocket ì •ë„ë§Œ ì¶”ê°€í•˜ì—¬ ìˆ˜ì›”í•˜ê²Œ ê°œë°œ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

## ì²˜ë¦¬ íë¦„

ì•Œë¦¼ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ì´ ë°œìƒí•  ê²½ìš° ìš”ê±´ì— ì¶©ì¡±í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ì´ ê°€ê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.    
í˜„ì¬ ì•Œë¦¼ì— í•´ë‹¹í•˜ëŠ” ì¡°ê±´ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- ë‚´ê°€ íŒ”ë¡œìš°í•œ ì‘ì„±ìê°€ ê¸€ ì‘ì„±
- ë‚´ê°€ ì“´ ê¸€ì— ëŒ“ê¸€ ë‹¬ë¦° ê²½ìš°
- ë‚´ ëŒ“ê¸€ì— ëŒ€ëŒ“ê¸€ì´ ë‹¬ë¦° ê²½ìš°
- ë‚˜ë¥¼ íŒ”ë¡œì‰í•œ ì‚¬ëŒì´ ë°œìƒí•œ ê²½ìš°
- ìš´ì˜ì ì œì¬ê°€ ë°œìƒí•œ ê²½ìš°

ë‚´ê°€ ì“´ ê¸€ì— ëŒ“ê¸€ ë‹¬ë¦° ê²½ìš°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

Kafkaì—ì„œ ì²˜ë¦¬ ë°©ì‹ì…ë‹ˆë‹¤.

```mermaid
graph LR
A[ì‚¬ìš©ì A ê¸€ ì‘ì„±] --> B[ì‚¬ìš©ì B, A ê¸€ì— ëŒ“ê¸€ ì‘ì„±] --> C{FastAPIì—ì„œ ë°ì´í„° íŒë³„ ë° ì²˜ë¦¬} 
C --> |Aê°€ Aê¸€ì— ëŒ“ê¸€ì„ ì‘ì„±| D[ì•Œë¦¼ ë¯¸ë°œì†¡]
C --> |Aê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì¸ì›ì´ ëŒ“ê¸€ì„ ì‘ì„±| E[Aì—ê²Œ ì•Œë¦¼ ë°œì†¡] --> F[Kafkaë¡œ Publish]
F[Kafkaë¡œ Publish] --> G[Consumeí•˜ì—¬ ë°ì´í„° ê°€ê³µ] --> H[DB ë° Redisì— ì €ì¥]
```

WebSocketì˜ ë™ì‘ì…ë‹ˆë‹¤.

```mermaid
graph LR
A[ì‚¬ìš©ìê°€ ì •ìƒ ë¡œê·¸ì¸] --> B[FastAPIì—ì„œ NextJSì™€ WebSocket ì—°ê²°, Redis Subscribe] --> C[Redis ë°ì´í„° ë°œìƒì‹œ FastAPI Subscribe]
--> D[WebSocketì„ ì‚¬ìš©í•˜ì—¬ NextJSì— ì „ë‹¬] --> E[NextJS í™”ë©´ ë³€í™”]
```

## ì‚¬ìš©ì ì•ŒëŒ í…Œì´ë¸” ìƒì„±

ì‹¤ì‹œê°„ìœ¼ë¡œë„ ë³´ì—¬ì£¼ì§€ë§Œ ì‚¬ìš©ìê°€ í™•ì¸í•˜ë”ë¼ë„, 7ì¼ì€ ìœ ì§€í•˜ê²Œ í•˜ê¸° ìœ„í•´ ìƒì„±í–ˆìŠµë‹ˆë‹¤.   
ì—¬ëŸ¬ê°€ì§€ ë™ì‘ì— ëŒ€í•´ ë°ì´í„° ê·œê²©ì„ í†µì¼í•˜ê°€ ì–´ë ¤ì›Œ jsonìœ¼ë¡œ ë§Œë“¤ê³  í™”ë©´ì—ì„œ ë³€í™˜í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.

```sql
CREATE TABLE IF NOT EXISTS user_notifications (
    id SERIAL PRIMARY KEY,
    user_email TEXT NOT NULL,
    noti_type TEXT NOT NULL,
    payload JSONB,
    is_read BOOLEAN DEFAULT FALSE,
    created_time TIMESTAMP DEFAULT NOW()
);
COMMENT ON COLUMN user_notifications.id IS 'ìë™ ìƒì„± ID';
COMMENT ON COLUMN user_notifications.user_email IS 'ì‚¬ìš©ì ì´ë©”ì¼';
COMMENT ON COLUMN user_notifications.noti_type IS 'ì•Œë¦¼ íƒ€ì…';
COMMENT ON COLUMN user_notifications.payload IS 'ì•Œë¦¼ ë‚´ìš©';
COMMENT ON COLUMN user_notifications.is_read IS 'ì•Œë¦¼ ì½ê¸° ì—¬ë¶€';
COMMENT ON COLUMN user_notifications.created_time IS 'ì•Œë¦¼ ìƒì„± ì‹œê°„';
```

## Code ì‘ì„±

Codeë¥¼ ì¶”ê°€í•  ë¶€ë¶„ì´ ë§ìŠµë‹ˆë‹¤.

NextJS, FastAPI, Kafka Consumer ì „ë¶€ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

### NextJS

NextJSì—ì„œëŠ” WebSocketì„ ì—°ê²°í•˜ëŠ” ë¶€ë¶„ì„ ì¶”ê°€í•©ë‹ˆë‹¤.   
useEffectì—ì„œ ì‚¬ìš©ìê°€ ë¡œê·¸ì¸ì„ í•œ ê²½ìš°ì— WebSocket ì—°ê²°ì„ ì§„í–‰í•©ë‹ˆë‹¤.   
ì¤‘ë³µìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ”ê²Œ ì¢€ ìˆì–´ì„œ í•„í„°ë§ë„ ì§„í–‰í•©ë‹ˆë‹¤.

```js
  useEffect(() => {
    if (!session?.accessToken) return;

    const ws = new WebSocket(
      `wss://${process.env.NEXT_PUBLIC_REDIS_HOST}/ws?token=${session.accessToken}`
    );

    ws.onmessage = (event) => {
      try {
        const parsed = JSON.parse(event.data);

        if (parsed.type === "init") {
          // ì´ˆê¸° ì•Œë¦¼ â†’ ì„œë²„ì—ì„œ ì´ë¯¸ JSONìœ¼ë¡œ ë³´ëƒˆìœ¼ë¯€ë¡œ ì¶”ê°€ parsing ë¶ˆí•„ìš”
          const initial = parsed.notifications as NotificationDataTypes[];
          setNotifications(initial);
        } else if (parsed.type === "message") {
          const newNotification = parsed.data as NotificationDataTypes;
          setNotifications((prev) => [...prev, newNotification]);
        } else {
          // type ì—†ëŠ” ê²½ìš°
          const newNotification = parsed as NotificationDataTypes;
          setNotifications((prev) => [...prev, newNotification]);
        }
      } catch (e) {
        console.error("ì•Œë¦¼ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨:", e, event.data);
      }
    };

    return () => {
      ws.close();
    };
  }, [session?.accessToken]);
```

### FastAPI

NextJSì™€ WebSocketì„ ì—°ê²°í•˜ë©´ì„œ Redisë¥¼ Subscribe í•˜ëŠ” ê²ƒë„ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ ì•Œë¦¼ ë™ì‘ì‹œ Kafkaë¡œ Publishë„ í•´ì•¼í•©ë‹ˆë‹¤.   
Redisì˜ í‚¤ëŠ” ì‚¬ìš©ìì˜ emailì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‘ì„± í›„ main.pyì—ì„œ FastAPIì˜ WebSocket ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì—°ê²°í•©ë‹ˆë‹¤.

> í•˜ë©´ì„œ ì¢€ ì–´ë ¤ì› ë˜ê²Œ ì¤‘ë³µì¸ ë°ì´í„°ê°€ ê³„ì† ìƒê¸°ëŠ” ë¬¸ì œê°€ ìˆì—ˆëŠ”ë°, ì¼ë‹¨ ë°ì´í„° í•„í„°ë§ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

```python
import asyncio
import json
import os
from typing import Dict, Set
from redis.asyncio import Redis
from fastapi import WebSocket

# Redis ì—°ê²°
redis = Redis.from_url(f"redis://{os.getenv('REDIS_HOST')}", decode_responses=True)

# WebSocket ì—°ê²° ì €ì¥
connected_websockets: Dict[str, WebSocket] = {}  # user_email -> websocket
user_listeners: Dict[str, asyncio.Task] = {}  # user_email -> listener task
sent_notifications: Dict[str, Set[str]] = {}  # user_email -> ì „ì†¡í•œ ì•Œë¦¼ ê³ ìœ  í‚¤


async def websocket_handler(websocket: WebSocket, user_email: str):
    """
    í´ë¼ì´ì–¸íŠ¸ WebSocket ì—°ê²° ì²˜ë¦¬
    """
    await websocket.accept()
    connected_websockets[user_email] = websocket

    # --------------------------
    # 1ï¸âƒ£ ì´ˆê¸° ì•Œë¦¼ ê°€ì ¸ì˜¤ê¸° + ì œê±°
    # --------------------------
    existing_notifications = []
    while True:
        n = await redis.lpop(f"notifications:{user_email}")
        if not n:
            break
        existing_notifications.append(json.loads(n))  # Redisì—ëŠ” json.dumpsë¡œ ì €ì¥ë¨

    # ìµœì‹  ìˆœì„œëŒ€ë¡œ ì „ë‹¬
    existing_notifications.reverse()

    await websocket.send_text(
        json.dumps({"type": "init", "notifications": existing_notifications})
    )

    # --------------------------
    # 2ï¸âƒ£ listener ìƒì„± (ì—†ìœ¼ë©´)
    # --------------------------
    if user_email not in user_listeners:
        user_listeners[user_email] = asyncio.create_task(redis_listener(user_email))

    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ (ì˜ˆ: pingìš©)
            await websocket.receive_text()
    except Exception:
        await cleanup_user(user_email)


async def redis_listener(user_email: str):
    """
    Redis Pub/Sub êµ¬ë… ë° ì‹¤ì‹œê°„ ì•Œë¦¼ ì „ì†¡
    """
    pubsub = redis.pubsub()
    await pubsub.subscribe(f"notifications_channel:{user_email}")

    if user_email not in sent_notifications:
        sent_notifications[user_email] = set()

    try:
        async for message in pubsub.listen():
            if message["type"] != "message":
                continue

            raw_data = message["data"]
            data = json.loads(raw_data)

            # --------------------------
            # 1ï¸âƒ£ ê³ ìœ  í‚¤ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
            # --------------------------
            notification_key = f"{data['noti_type']}_{data.get('post_id')}_{data.get('parent_comment_id')}_{data.get('author_email')}_{data.get('id')}"

            if notification_key in sent_notifications[user_email]:
                continue

            sent_notifications[user_email].add(notification_key)

            ws = connected_websockets.get(user_email)
            if ws:
                try:
                    # í•­ìƒ JSON ë¬¸ìì—´ë¡œ í†µì¼
                    await ws.send_text(json.dumps({"type": "message", "data": data}))
                except Exception:
                    await cleanup_user(user_email)
                    break

    except asyncio.CancelledError:
        pass
    finally:
        await pubsub.unsubscribe(f"notifications_channel:{user_email}")
        await pubsub.close()


async def cleanup_user(user_email: str):
    """
    íŠ¹ì • ìœ ì € ê´€ë ¨ WebSocket, listener, sent_notifications ì •ë¦¬
    """
    connected_websockets.pop(user_email, None)

    if user_email in user_listeners:
        user_listeners[user_email].cancel()
        await user_listeners.pop(user_email, None)

    sent_notifications.pop(user_email, None)

# main.py
from util.websocket import websocket_handler

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, token: str = Query(...)):
    """
    ë¡œê·¸ì¸í•œ ì‚¬ìš©ìë§Œ WebSocket ì—°ê²°
    í† í°ì€ query paramìœ¼ë¡œ ì „ë‹¬
    """
    user_email = UserUtil.verify_google_token(token)
    if not user_email:
        await websocket.close(code=1008)  # ì •ì±… ìœ„ë°˜
        return

    await websocket_handler(websocket, user_email)

# Publish ë™ì‘
# ë³¸ì¸ì´ ì‘ì„±í•œ ê±°ëŠ” ë¬´ì‹œ
if request_info.post_author_email != user_email:
    kafka_message = {
        "url": f"{bigint_post_id}-{request_info.slug}?comment_id={new_id}",
        "author_email": user_email,
        "post_id": bigint_post_id,
        "author_nickname": request_info.nickname,
        "title": request_info.title,
        "noti_type": "create_parent_comment",
    }
    json_str = json.dumps(kafka_message)
    produce_notification(json_str)

# ì „ì†¡
def produce_notification(value: str):
    producer.produce(
        NOTIFICATION_TOPIC, value=value.encode("utf-8"), callback=delivery_report
    )
    producer.poll(0)
    producer.flush(0.2)
```

### Kafka Consumer

Kafka Consumer ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” Consume í›„ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ Redisì™€ DBì— ì ì¬í•©ë‹ˆë‹¤.

ì‚¬ìš©ì ë™ì‘ë§ˆë‹¤ ê°œë³„ë¡œ processë¥¼ ëŒë ¤ì„œ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ê³  ì ì¬í•©ë‹ˆë‹¤. ë˜í•œ ì¿¼ë¦¬ë„ ì „ë¶€ ë‹¤ë¥´ê²Œ ì‚¬ìš©í•©ë‹ˆë‹¤. 

> ì—¬ê¸°ê°€ ì¡°ê¸ˆ ë³µì¡í•©ë‹ˆë‹¤. í•œ ë²ˆ ë†“ì¹˜ë©´ ì—‰ì¼œë²„ë¦½ë‹ˆë‹¤.

```python
import json
import redis
from consumer.pg_client import get_pg_connection
from consumer.logger import logger
import os
from dotenv import load_dotenv

load_dotenv()
pg_conn = get_pg_connection()
logger.info("ì•Œë¦¼ DB ì—°ê²° ì„±ê³µ")

# Redis ì—°ê²°
redis_client = redis.StrictRedis(
    host=os.getenv("REDIS_HOST"),
    port=int(os.getenv("REDIS_PORT")),
    db=int(os.getenv("REDIS_DB")),
    decode_responses=True,
)
logger.info("Redis ì—°ê²° ì„±ê³µ")

NOTIFICATION_HANDLERS = {
    "create_post": {
        "query": """
            INSERT INTO user_notifications (user_email, noti_type, payload)
            SELECT uf.following_email, %(noti_type)s, %(payload)s
            FROM user_follows uf
            WHERE uf.follower_email = %(author_email)s
            RETURNING user_email
        """,
        "param_builder": lambda data: {
            "noti_type": data["noti_type"],
            "payload": json.dumps(data),
            "author_email": data["author_email"],
        },
    },
    "create_parent_comment": {
        "query": """
            INSERT INTO user_notifications (user_email, noti_type, payload)
            SELECT cp.user_email, %(noti_type)s, %(payload)s
            FROM community_posts cp
            WHERE cp.id = %(post_id)s
            RETURNING user_email
        """,
        "param_builder": lambda data: {
            "noti_type": data["noti_type"],
            "payload": json.dumps(data),
            "post_id": data["post_id"],
        },
    },
    "create_child_comment": {
        "query": """
            INSERT INTO user_notifications (user_email, noti_type, payload)
            SELECT cc.user_email, %(noti_type)s, %(payload)s
            FROM community_comments cc
            WHERE cc.id = %(parent_comment_id)s
            RETURNING user_email
        """,
        "param_builder": lambda data: {
            "noti_type": data["noti_type"],
            "payload": json.dumps(data),
            "parent_comment_id": data["parent_comment_id"],
        },
    },
    "follow_user": {
        "query": """
            INSERT INTO user_notifications (user_email, noti_type, payload)
            SELECT ui.email, %(noti_type)s, %(payload)s
            FROM user_info ui
            WHERE ui.email = %(follower_email)s
            RETURNING user_email
        """,
        "param_builder": lambda data: {
            "noti_type": data["noti_type"],
            "payload": json.dumps(data),
            "follower_email": data["follower_email"],
        },
    },
    "penalty_user": {
        "query": """
            INSERT INTO user_notifications (user_email, noti_type, payload)
            VALUES (%(user_email)s, %(noti_type)s, %(payload)s)
            RETURNING user_email
        """,
        "param_builder": lambda data: {
            "user_email": data["user_email"],
            "noti_type": data["noti_type"],
            "payload": json.dumps(data),
        },
    },
}


def save_notifications_and_push_to_redis(cur, query, params, data):
    """
    ê³µí†µ í•¨ìˆ˜: DBì— ì•Œë¦¼ ì €ì¥ í›„ Redisì— push
    """
    cur.execute(query, params)
    notified_users = [row[0] for row in cur.fetchall()]
    pg_conn.commit()

    for user_email in notified_users:
        redis_key = f"notifications:{user_email}"
        redis_client.lpush(redis_key, json.dumps(data))
        redis_client.expire(redis_key, 60 * 60 * 24 * 7)  # TTL 7ì¼
        # âœ… WebSocketìš© pub/sub push
        redis_client.publish(f"notifications_channel:{user_email}", json.dumps(data))

    return notified_users


def process_notification_message(data):
    """
    ì•Œë¦¼ ì²˜ë¦¬í•˜ê¸°
    """
    handler = NOTIFICATION_HANDLERS.get(data["noti_type"])
    if not handler:
        logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•Œë¦¼ íƒ€ì…: {data['noti_type']}")
        return

    try:
        with pg_conn.cursor() as cur:
            insert_query = handler["query"]
            params = handler["param_builder"](data)
            save_notifications_and_push_to_redis(cur, insert_query, params, data)
        logger.info(f"ì•Œë¦¼ ì²˜ë¦¬ ì™„ë£Œ: {data} (Redis Save)")
    except Exception as e:
        logger.error(f"ì•Œë¦¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        pg_conn.rollback()

```

## ê²°ê³¼

ì´ì œ ì•„ì´ë”” 2ê°œë¥¼ ì‚¬ìš©í•˜ì—¬ ì—°ê²°ì´ ì˜ ë˜ì—ˆë‚˜ í™•ì¸í•´ë³´ë©´ ë©ë‹ˆë‹¤.
https://github.com/user-attachments/assets/dce64424-9cb4-4edd-b95f-2818ad41037a


